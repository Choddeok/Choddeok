# Deok-Hyeon Cho
Integrated M.S.&Ph.D Student

Department of Artificial Intelligence Korea University, Seoul, South Korea

- Research Interests: Emotional Speech Synthesis
- E-mail: dh_cho@korea.ac.kr
- Google Scholar: [Link](https://scholar.google.co.kr/citations?user=cynqcHwAAAAJ&hl=ko)
- LinkedIn: [Link](https://www.linkedin.com/in/deok-hyeon-cho-7b5222204/)

## üî≠ Employment History
- **[2022 ‚Äì 2022] RexSoft (Intern)**
  
  - Participated in debugging and development of the REX program in the Development Department.
 
- **[2022 ‚Äì 2022] Visang Education (Intern)**

  - Assisted with data entry, validation, analysis, and report creation for the E-Learning Content Planning Department.
 
## üå± Education
- **[2016 ‚Äì 2022] Hanyang University, Ansan, South Korea.**

  - B.S. degree in Applied Mathematics.
 
- **[2022 ‚Äì ] Korea University, Seoul, South Korea.**

  - Integrated M.S.&Ph.D. in Artificial Intelligence in [Pattern Recognition & Machine Learning Lab](http://ibi.korea.ac.kr/sub2_1.php?code=LSW), under the supervision of Seong-Whan Lee.

## üìë Research Publications
**[2025]**
- **D.-H. Cho**, H.-S. Oh, S.-B. Kim, and S.-W. Lee, ‚ÄúEmoSphere++: Emotion-Controllable Zero-Shot Text-to-Speech via Emotion-Adaptive Spherical Vector,‚Äù *in Proc. IEEE Transactions on Affective Computing (TAFFC)*, 2025. [[Paper]](https://ieeexplore.ieee.org/document/10965917) [[Code]](https://github.com/Choddeok/EmoSpherepp) [[Demo]](https://choddeok.github.io/EmoSphere-Demo/)

- H.-S. Oh, S.-H. Lee, **D.-H. Cho**, and S.-W. Lee, ‚ÄúDurFlex-EVC: Duration-Flexible Emotional Voice Conversion Leveraging Discrete Representations Without Text Alignment,‚Äù *in Proc. IEEE Transactions on Affective Computing (TAFFC)*, 2025. [[Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10844546) [[Code]](https://github.com/hs-oh-prml/DurFlexEVC?tab=readme-ov-file) [[Demo]](https://prml-lab-speech-team.github.io/durflex/)

**[2024]**
- J.-E. Lee, S.-B. Kim, **D.-H. Cho**, and S.-W. Lee, ‚ÄúPromotiCon: Prompt-Based Emotion Controllable Text-to-Speech via Prompt Generation and Matching,‚Äù *in Proc. IEEE International Conference on Systems, Man, and Cybernetics (SMC)*, 2024. [[paper]](https://ieeexplore.ieee.org/document/10831218) [[Demo]](https://promoticon.github.io/.)

- **D.-H. Cho**, H.-S. Oh, S.-B. Kim, S.-H. Lee, and S.-W. Lee, ‚ÄúEmoSphere-TTS: Emotional Style and Intensity Modeling via Spherical Emotion Vector for Controllable Emotional Text-to-Speech,‚Äù *in Proc. Conference of the International Speech Communication Association (INTERSPEECH)*, 2024. [[Paper]](https://www.isca-archive.org/interspeech_2024/cho24_interspeech.html) [[Code]](https://github.com/Choddeok/EmoSphere-TTS) [[Demo]](https://emosphere-tts.github.io/)

## üèÜ Awards and Achievements
- [2021] Excellence Award in the Credit Card User Delinquency Prediction AI Competition, organized by Hanyang University on Dacon.


<!--
**Choddeok/Choddeok** is a ‚ú® _special_ ‚ú® repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- üî≠ I‚Äôm currently working on ...
- üå± I‚Äôm currently learning ...
- üëØ I‚Äôm looking to collaborate on ...
- ü§î I‚Äôm looking for help with ...
- üí¨ Ask me about ...
- üì´ How to reach me: ...
- üòÑ Pronouns: ...
- ‚ö° Fun fact: ...
-->
