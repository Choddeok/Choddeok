# Deok-Hyeon Cho
Integrated M.S.&Ph.D Student

Department of Artificial Intelligence Korea University, Seoul, South Korea

- Research Interests: Emotional Speech Synthesis
- E-mail: dh_cho@korea.ac.kr
- Google Scholar: [Link](https://scholar.google.co.kr/citations?user=cynqcHwAAAAJ&hl=ko)
- LinkedIn: [Link](https://www.linkedin.com/in/deok-hyeon-cho-7b5222204/)

## üî≠ Employment History
- **[2022 ‚Äì 2022] RexSoft (Intern)**
  
  - Participated in debugging and development of the REX program in the Development Department.
 
- **[2022 ‚Äì 2022] Visang Education (Intern)**

  - Assisted with data entry, validation, analysis, and report creation for the E-Learning Content Planning Department.
 
## üå± Education
- **[2016 ‚Äì 2022] Hanyang University, Ansan, South Korea.**

  - B.S. degree in Applied Mathematics.
 
- **[2022 ‚Äì ] Korea University, Seoul, South Korea.**

  - Integrated M.S.&Ph.D. in Artificial Intelligence in [Pattern Recognition & Machine Learning Lab](http://ibi.korea.ac.kr/sub2_1.php?code=LSW), under the supervision of Seong-Whan Lee.

## üìë Research Publications
- **D.-H. Cho**, H.-S. Oh, S.-B. Kim, S.-H. Lee, and S.-W. Lee, ‚ÄúEmosphere-tts: Emotional style and intensity modeling via spherical emotion vector for controllable emotional text-to-speech,‚Äù in Proc. Conference of the International Speech Communication Association (INTERSPEECH), 2024. [[Paper]](https://arxiv.org/pdf/2406.07803) [[Code]](https://github.com/Choddeok/EmoSphere-TTS) [[Demo]](https://emosphere-tts.github.io/)

- J.-E. Lee, S.-B. Kim, **D.-H. Cho**, and S.-W. Lee, ‚ÄúPromoticon: Prompt-based emotion controllable text-to-speech via prompt generation and matching,‚Äù in Proc. IEEE International Conference on Systems, Man, and Cybernetics (SMC), 2024.

- H.-S. Oh, S.-H. Lee, **D.-H. Cho**, and S.-W. Lee, ‚ÄúDurflex-evc: Duration-flexible emotional voice conversion with parallel generation,‚Äù in (Under Review), 2024. [[Paper]](https://arxiv.org/pdf/2401.08095) [[Code]](https://github.com/hs-oh-prml/DurFlexEVC?tab=readme-ov-file) [[Demo]](https://prml-lab-speech-team.github.io/durflex/)

- **D.-H. Cho**, H.-S. Oh, S.-B. Kim, and S.-W. Lee, ‚ÄúEmoSphere++: Emotion-Controllable Zero-Shot Text-to-Speech via Emotion-Adaptive Spherical Vector,‚Äù in (Under Review), 2024. [[Paper]](https://arxiv.org/abs/2411.02625) [[Code]](https://github.com/Choddeok/EmoSpherepp) [[Demo]](https://choddeok.github.io/EmoSphere-Demo/)

## üèÜ Awards and Achievements
- [2021] Excellence Award in the Credit Card User Delinquency Prediction AI Competition, organized by Hanyang University on Dacon.


<!--
**Choddeok/Choddeok** is a ‚ú® _special_ ‚ú® repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- üî≠ I‚Äôm currently working on ...
- üå± I‚Äôm currently learning ...
- üëØ I‚Äôm looking to collaborate on ...
- ü§î I‚Äôm looking for help with ...
- üí¨ Ask me about ...
- üì´ How to reach me: ...
- üòÑ Pronouns: ...
- ‚ö° Fun fact: ...
-->
