
![welcome little one!](https://github.com/user-attachments/assets/290ce339-84ca-4028-b82c-0929853f590a)

<h1 align="center">Deok-Hyeon Cho (ì¡°ë•í˜„) </h1>

<p align="center">
  <a href="mailto:dh_cho@korea.ac.kr">
    <img src="https://img.shields.io/badge/Email-dh_cho%40korea.ac.kr-blue?style=flat&logo=gmail" alt="Email Badge"/>
  </a>
  <a href="https://scholar.google.co.kr/citations?user=cynqcHwAAAAJ&hl=en">
    <img src="https://img.shields.io/badge/Google%20Scholar-Profile-orange?style=flat&logo=google-scholar" alt="Google Scholar Badge"/>
  </a>
  <a href="https://www.linkedin.com/in/deokhyeon-cho-7b5222204">
    <img
      src="https://img.shields.io/badge/LinkedIn-Deokâ€“Hyeon%20Cho-0077B5?style=flat&logo=linkedin&logoColor=white"
      alt="LinkedIn Badge"
    />
  </a>
</p>

<p align="center"><em>Ph.D. Candidate, Department of Artificial Intelligence, Korea University</em></p>

<p align="center">
  <strong>Research in Affective Computing:</strong><br/>
  Emotional Speech Synthesis â€¢ Emotion Recognition â€¢ Emotional Voice Conversion â€¢ Multimodal Affective Modeling
</p>

<p align="center">
  <a href="https://github.com/user-attachments/files/20328954/250520_CV.pdf"
     target="_blank" rel="noopener">
    <strong>Download CV</strong>
  </a>
</p>

## ğŸ’¼ Employment History

- **[RexSoft](https://rexsoft.org/) (Intern) | Development Department (2022)**  
   - Debugged and enhanced the REX program


- **[Visang Education](https://www.visang.com/pageLoad?page_id=/en/main) (Intern) | E-Learning Content Planning Department (2021)**  
   - Managed data entry, validation, analysis, and report creation


## ğŸ“ Education

- **[2022 â€“ ] Korea University, Seoul, South Korea.**
  - Integrated M.S.&Ph.D. in Artificial Intelligence in [Pattern Recognition & Machine Learning Lab](http://ibi.korea.ac.kr/sub2_1.php?code=LSW), under the supervision of Seong-Whan Lee.
  - GPA: 4.19 / 4.50
  
- **[2016 â€“ 2022] Hanyang University, Ansan, South Korea.**
  - B.S. degree in Applied Mathematics.
  - GPA: 4.40 / 4.50

## ğŸ“‘ Research Publications

**[2025]**
- **D.-H. Cho**, H.-S. Oh, S.-B. Kim, and S.-W. Lee, â€œDiEmo-TTS: Disentangled Emotion Representations via Self-Supervised Distillation for Cross-Speaker Emotion Transfer in Text-to-Speech,â€ *in Proc. Conference of the International Speech Communication Association (INTERSPEECH)*, 2025.
   - [[ğŸ“„ Paper]](https://arxiv.org/abs/2505.19687) [[ğŸ’» Code]](https://github.com/Choddeok/DiEmoTTS) [[ğŸ¤ Demo]](https://choddeok.github.io/DiEmo-TTS-Demo/)

- N.-G. Kim, **D.-H. Cho**, S.-B. Kim, and S.-W. Lee, â€œSpotlight-TTS: Spotlighting the Style via Voiced-Aware Style Extraction and Style Direction Adjustment for Expressive Text-to-Speech,â€ *in Proc. Conference of the International Speech Communication Association (INTERSPEECH)*, 2025.
   - [[ğŸ“„ Paper]](https://arxiv.org/abs/2505.20868) [[ğŸ¤ Demo]](https://spotlight-tts.github.io/)

- **D.-H. Cho***, H.-S. Oh*, S.-B. Kim*, and S.-W. Lee, â€œEmoSphere-SER: Enhancing Speech Emotion Recognition through Spherical Representation with Auxiliary Classification,â€ *in Proc. Conference of the International Speech Communication Association Challenge (Speech Emotion Recognition in Naturalistic Conditions Challenge)*, 2025.
   - [[ğŸ“„ Paper]](https://arxiv.org/abs/2505.19693) [[ğŸ’» Code]](https://github.com/Choddeok/EmoSphereSER)

- **D.-H. Cho**, H.-S. Oh, S.-B. Kim, and S.-W. Lee, â€œEmoSphere++: Emotion-Controllable Zero-Shot Text-to-Speech via Emotion-Adaptive Spherical Vector,â€ *in Proc. IEEE Transactions on Affective Computing (TAFFC)*, 2025. ![](https://img.shields.io/badge/2023--JCR--IF-9.6-red) ![](https://img.shields.io/badge/JIF%20Top%201.6%25-red)
   - [[ğŸ“„ Paper]](https://ieeexplore.ieee.org/document/10965917) [[ğŸ’» Code]](https://github.com/Choddeok/EmoSpherepp) [[ğŸ¤ Demo]](https://choddeok.github.io/EmoSphere-Demo/)

- H.-S. Oh, S.-H. Lee, **D.-H. Cho**, and S.-W. Lee, â€œDurFlex-EVC: Duration-Flexible Emotional Voice Conversion Leveraging Discrete Representations Without Text Alignment,â€ *in Proc. IEEE Transactions on Affective Computing (TAFFC)*, 2025. ![](https://img.shields.io/badge/2023--JCR--IF-9.6-red) ![](https://img.shields.io/badge/JIF%20Top%201.6%25-red)
   - [[ğŸ“„ Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10844546) [[ğŸ’» Code]](https://github.com/hs-oh-prml/DurFlexEVC?tab=readme-ov-file) [[ğŸ¤ Demo]](https://prml-lab-speech-team.github.io/durflex/)

**[2024]**
- J.-E. Lee, S.-B. Kim, **D.-H. Cho**, and S.-W. Lee, â€œPromotiCon: Prompt-Based Emotion Controllable Text-to-Speech via Prompt Generation and Matching,â€ *in Proc. IEEE International Conference on Systems, Man, and Cybernetics (SMC)*, 2024.
   - [[ğŸ“„ paper]](https://ieeexplore.ieee.org/document/10831218) [[ğŸ¤ Demo]](https://promoticon.github.io/.)

- **D.-H. Cho**, H.-S. Oh, S.-B. Kim, S.-H. Lee, and S.-W. Lee, â€œEmoSphere-TTS: Emotional Style and Intensity Modeling via Spherical Emotion Vector for Controllable Emotional Text-to-Speech,â€ *in Proc. Conference of the International Speech Communication Association (INTERSPEECH)*, 2024.
   - [[ğŸ“„ Paper]](https://www.isca-archive.org/interspeech_2024/cho24_interspeech.html) [[ğŸ’» Code]](https://github.com/Choddeok/EmoSphere-TTS) [[ğŸ¤ Demo]](https://emosphere-tts.github.io/)


## ğŸ’» Research Projects
- A Study on Nonverval (Filler) Speech
   - Institution: Samsung Research, Korea
   - Duration: May. 2024 ~ Dec. 2024

## ğŸ† Awards & Achievements

- ğŸ¥‡ **Excellence Award** (2021)  
  Credit Card User Delinquency Prediction AI Competition â€” Hanyang University & Dacon

- Reviewer: IEEE International Conference on Systems, Man, and Cybernetics (SMC)

## ğŸ“‘ Patents (KR)
- Apparatus and Method for Speech Synthesis, 10-2025-0088028.

- Method, Device, and Program for synthesizing voices Expressing emotions Based on Prompts, 10-2024-0099370.

- Emotional Expression Voice Generation Apparatus and Method Capable of Controlling Emotional Style and Intensity Using Continuous Emotional Dimensions, 10-2024-0029066.
