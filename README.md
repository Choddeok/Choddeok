
![welcome little one!](https://github.com/user-attachments/assets/290ce339-84ca-4028-b82c-0929853f590a)

<h1 align="center">Deok-Hyeon Cho (ì¡°ë•í˜„) </h1>

<p align="center">
  <a href="mailto:dh_cho@korea.ac.kr">
    <img src="https://img.shields.io/badge/Email-dh_cho%40korea.ac.kr-blue?style=flat&logo=gmail" alt="Email Badge"/>
  </a>
  <a href="https://scholar.google.co.kr/citations?user=cynqcHwAAAAJ&hl=en">
    <img src="https://img.shields.io/badge/Google%20Scholar-Profile-orange?style=flat&logo=google-scholar" alt="Google Scholar Badge"/>
  </a>
  <a href="https://www.linkedin.com/in/deokhyeon-cho-7b5222204">
    <img
      src="https://img.shields.io/badge/LinkedIn-Deokâ€“Hyeon%20Cho-0077B5?style=flat&logo=linkedin&logoColor=white"
      alt="LinkedIn Badge"
    />
  </a>
</p>

<p align="center"><em>Ph.D. Candidate, Department of Artificial Intelligence, Korea University</em></p>

<p align="center">
  <strong>Research in Affective Computing:</strong><br/>
  Emotional Speech Synthesis â€¢ Emotion Recognition â€¢ Emotional Voice Conversion â€¢ Multimodal Affective Modeling
</p>

<p align="center">
  <a href="https://github.com/user-attachments/files/24557207/CV_260107.pdf"
     target="_blank" rel="noopener">
    <strong>Download CV</strong>
  </a>
</p>

## ğŸ’¼ Employment History

- **[2022] [RexSoft](https://rexsoft.org/) (Intern) | Development Department**  
   - Debugged and enhanced the REX program


- **[2021] [Visang Education](https://www.visang.com/pageLoad?page_id=/en/main) (Intern) | E-Learning Content Planning Department (2021)**  
   - Managed data entry, validation, analysis, and report creation


## ğŸ“ Education

- **[2022 â€“ ] Korea University, Seoul, South Korea.**
  - Integrated M.S.&Ph.D. in Artificial Intelligence in [Pattern Recognition & Machine Learning Lab](http://ibi.korea.ac.kr/sub2_1.php?code=LSW), under the supervision of Seong-Whan Lee.
  - GPA: 4.19 / 4.50
  
- **[2016 â€“ 2022] Hanyang University, Ansan, South Korea.**
  - B.S. degree in Applied Mathematics.
  - GPA: 4.40 / 4.50

## ğŸ“‘ Research Publications

**[2026]**
- H.-S. Oh, **D.-H. Cho**, S.-B. Kim, and S.-W. Lee, â€œToward Complex-Valued Neural Networks for Waveform Generation,â€ *in Proc. Conference of the International Conference on Learning Representations (ICLR)*, 2026.
   - [[ğŸ“„ Paper]](https://openreview.net/forum?id=U4GXPqm3Va) [[ğŸ’» Code]]() [[ğŸ¤ Demo]]()

**[2025]**
- **D.-H. Cho**, H.-S. Oh, S.-B. Kim, and S.-W. Lee, â€œDiEmo-TTS: Disentangled Emotion Representations via Self-Supervised Distillation for Cross-Speaker Emotion Transfer in Text-to-Speech,â€ *in Proc. Conference of the International Speech Communication Association (INTERSPEECH)*, 2025.
   - [[ğŸ“„ Paper]](https://www.isca-archive.org/interspeech_2025/cho25b_interspeech.html) [[ğŸ’» Code]](https://github.com/Choddeok/DiEmo-TTS) [[ğŸ¤ Demo]](https://choddeok.github.io/DiEmo-TTS-Demo/)

- N.-G. Kim, **D.-H. Cho**, S.-B. Kim, and S.-W. Lee, â€œSpotlight-TTS: Spotlighting the Style via Voiced-Aware Style Extraction and Style Direction Adjustment for Expressive Text-to-Speech,â€ *in Proc. Conference of the International Speech Communication Association (INTERSPEECH)*, 2025.
   - [[ğŸ“„ Paper]](https://www.isca-archive.org/interspeech_2025/kim25t_interspeech.html) [[ğŸ¤ Demo]](https://spotlight-tts.github.io/)

- **D.-H. Cho***, H.-S. Oh*, S.-B. Kim*, and S.-W. Lee, â€œEmoSphere-SER: Enhancing Speech Emotion Recognition through Spherical Representation with Auxiliary Classification,â€ *in Proc. Conference of the International Speech Communication Association (INTERSPEECH)*, 2025.
   - [[ğŸ“„ Paper]](https://www.isca-archive.org/interspeech_2025/cho25_interspeech.html) [[ğŸ’» Code]](https://github.com/Choddeok/EmoSphere-SER)

- **D.-H. Cho**, H.-S. Oh, S.-B. Kim, and S.-W. Lee, â€œEmoSphere++: Emotion-Controllable Zero-Shot Text-to-Speech via Emotion-Adaptive Spherical Vector,â€ *in Proc. IEEE Transactions on Affective Computing (TAFFC)*, 2025. ![](https://img.shields.io/badge/2023--JCR--IF-9.6-red) ![](https://img.shields.io/badge/JIF%20Top%201.6%25-red)
   - [[ğŸ“„ Paper]](https://ieeexplore.ieee.org/document/10965917) [[ğŸ’» Code]](https://github.com/Choddeok/EmoSpherepp) [[ğŸ¤ Demo]](https://choddeok.github.io/EmoSphere-Demo/)

- H.-S. Oh, S.-H. Lee, **D.-H. Cho**, and S.-W. Lee, â€œDurFlex-EVC: Duration-Flexible Emotional Voice Conversion Leveraging Discrete Representations Without Text Alignment,â€ *in Proc. IEEE Transactions on Affective Computing (TAFFC)*, 2025. ![](https://img.shields.io/badge/2023--JCR--IF-9.6-red) ![](https://img.shields.io/badge/JIF%20Top%201.6%25-red)
   - [[ğŸ“„ Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10844546) [[ğŸ’» Code]](https://github.com/hs-oh-prml/DurFlexEVC?tab=readme-ov-file) [[ğŸ¤ Demo]](https://prml-lab-speech-team.github.io/durflex/)

**[2024]**
- J.-E. Lee, S.-B. Kim, **D.-H. Cho**, and S.-W. Lee, â€œPromotiCon: Prompt-Based Emotion Controllable Text-to-Speech via Prompt Generation and Matching,â€ *in Proc. IEEE International Conference on Systems, Man, and Cybernetics (SMC)*, 2024.
   - [[ğŸ“„ paper]](https://ieeexplore.ieee.org/document/10831218) [[ğŸ¤ Demo]](https://promoticon.github.io/.)

- **D.-H. Cho**, H.-S. Oh, S.-B. Kim, S.-H. Lee, and S.-W. Lee, â€œEmoSphere-TTS: Emotional Style and Intensity Modeling via Spherical Emotion Vector for Controllable Emotional Text-to-Speech,â€ *in Proc. Conference of the International Speech Communication Association (INTERSPEECH)*, 2024.
   - [[ğŸ“„ Paper]](https://www.isca-archive.org/interspeech_2024/cho24_interspeech.html) [[ğŸ’» Code]](https://github.com/Choddeok/EmoSphere-TTS) [[ğŸ¤ Demo]](https://emosphere-tts.github.io/)


## ğŸ’» Research Projects
#### 1. Development of interjection utterances for natural speech synthesis
   - Institution: Samsung Research, Korea
   - Duration: May. 2024 ~ Dec. 2024

#### 2. Cross-speaker controllable emotion transfer TTS (Voltron)
   - Institution: Thomasâ€¯Crown, USA
   - Duration: Oct. 2025

## ğŸ† Awards & Achievements

- [2021] **Excellence Award**  
  Credit Card User Delinquency Prediction AI Competition â€” Hanyang University & Dacon

- [2025] **Excellence Award**  
  Extreme-Noise Speech Recognition & Restoration AI Model Development Competition [(AI Frontier Challenge)](https://aiassociation.kr/board/board.asp?b_code=243&Action=content&GotoPage=1&B_CATE=BBS1) â€” Korea Artificial Intelligence Association (KAIA)


- Reviewer: Transactions on Affective Computing (TAFFC), IEEE International Conference on Acoustics Speech and Signal Processing (ICASSP), IEEE International Conference on Systems, Man, and Cybernetics (SMC)

## ğŸ“‘ Patents (KR)
- Method for Cross-Speaker Emotion Transfer in Text-to-Speech Using Disentangled Emotion Representations via Self-Supervised Distillation, 10-2025-0130127.

- Method and System for Expressive Text-to-Speech via Voiced-Aware Style Extraction and Style Direction Adjustment, 10-2025-0116457.

- Apparatus and Method for Speech Synthesis, 10-2025-0088028.

- Method, Device, and Program for synthesizing voices Expressing emotions Based on Prompts, 10-2024-0099370.

- Emotional Expression Voice Generation Apparatus and Method Capable of Controlling Emotional Style and Intensity Using Continuous Emotional Dimensions, 10-2024-0029066.
